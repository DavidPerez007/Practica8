{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "BIlO7QbbD4-s",
      "metadata": {
        "id": "BIlO7QbbD4-s"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "848153e3",
      "metadata": {
        "id": "848153e3"
      },
      "source": [
        "# Laboratorio 8: Random Forest y despliegues\n",
        "\n",
        "**Duración:** 2 horas  \n",
        "**Formato:** Implementación, despliegue y competencia  \n",
        "\n",
        "---\n",
        "\n",
        "## Portada del equipo\n",
        "\n",
        "**Integrantes:**\n",
        "- Nombre 1 (Usuario GitHub)\n",
        "- Nombre 2 (Usuario GitHub)\n",
        "- Nombre 3 (Usuario GitHub)\n",
        "\n",
        "**Repositorio del equipo:**  \n",
        "<https://github.com/usuario/equipoX>\n",
        "\n",
        "**Fecha de entrega:**  \n",
        "__/__/____"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "067997e4",
      "metadata": {
        "id": "067997e4"
      },
      "source": [
        "## Elemento 1 - Implementación del Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "s2mUL5kmD80s",
      "metadata": {
        "id": "s2mUL5kmD80s"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv('iris_train.csv')\n",
        "X,y=df.iloc[:,:-1].values,df.iloc[:,-1].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "d12dcd31",
      "metadata": {
        "id": "d12dcd31"
      },
      "outputs": [],
      "source": [
        "class RandomForest:\n",
        "  def __init__(self, n_estimators=100, max_depth=None, max_features='sqrt', random_state=17):\n",
        "    self.n_estimators = n_estimators\n",
        "    self.max_depth = max_depth\n",
        "    self.max_features = max_features\n",
        "    self.random_state = random_state\n",
        "    self.trees = []\n",
        "\n",
        "  def bootstrap(self, X, y):\n",
        "    n_samples = len(X)\n",
        "    idxs = np.random.choice(n_samples, n_samples, replace=True)\n",
        "    return X[idxs], y[idxs]\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    self.trees = []\n",
        "    n_features = X.shape[1]\n",
        "\n",
        "    if self.max_features == 'sqrt':\n",
        "      self.max_features_num = max(1, int(np.sqrt(n_features)))\n",
        "    elif self.max_features == 'log2':\n",
        "      self.max_features_num = max(1, int(np.log2(n_features)))\n",
        "    else:\n",
        "      self.max_features_num = n_features\n",
        "\n",
        "    # Handle max_depth based on string inputs 'sqrt' or 'log2'\n",
        "    if self.max_depth == 'sqrt':\n",
        "        self.max_depth_num = max(1, int(np.sqrt(n_features)))\n",
        "    elif self.max_depth == 'log2':\n",
        "        self.max_depth_num = max(1, int(np.log2(n_features)))\n",
        "    else:\n",
        "        self.max_depth_num = self.max_depth # Use the provided integer or None\n",
        "\n",
        "\n",
        "    for i in range(self.n_estimators):\n",
        "      tree = DecisionTreeClassifier(max_depth=self.max_depth_num, max_features=self.max_features_num, random_state=self.random_state + i)\n",
        "\n",
        "      X_sample, y_sample = self.bootstrap(X, y)\n",
        "      tree.fit(X_sample, y_sample)\n",
        "      self.trees.append(tree)\n",
        "\n",
        "\n",
        "  def predict(self, X):\n",
        "    tree_preds = np.array([tree.predict(X) for tree in self.trees])\n",
        "    # Use axis=0 for column-wise operation\n",
        "    return np.array([np.argmax(np.bincount(tree_preds[:, i])) for i in range(tree_preds.shape[1])])\n",
        "\n",
        "\n",
        "  def fit_predict(self, X, y):\n",
        "    self.fit(X, y)\n",
        "    return self.predict(X)\n",
        "\n",
        "  def get_params(self, deep=True):\n",
        "    return {'n_estimators': self.n_estimators, 'max_depth': self.max_depth, 'max_features': self.max_features, 'random_state': self.random_state}\n",
        "\n",
        "  def set_params(self, **params):\n",
        "    for key, value in params.items():\n",
        "      setattr(self, key, value)\n",
        "    return self"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "m6_escf_El9s",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "m6_escf_El9s",
        "outputId": "b21537dd-45dc-4923-8c79-497036c2ee47"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>123.000000</td>\n",
              "      <td>123.000000</td>\n",
              "      <td>124.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>125.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5.821221</td>\n",
              "      <td>2.764442</td>\n",
              "      <td>3.909994</td>\n",
              "      <td>1.186667</td>\n",
              "      <td>0.984000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.428445</td>\n",
              "      <td>2.174626</td>\n",
              "      <td>2.484749</td>\n",
              "      <td>0.758474</td>\n",
              "      <td>0.822898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-11.601111</td>\n",
              "      <td>-14.870849</td>\n",
              "      <td>1.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>5.100000</td>\n",
              "      <td>2.700000</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.700000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.250000</td>\n",
              "      <td>1.300000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.400000</td>\n",
              "      <td>3.300000</td>\n",
              "      <td>5.100000</td>\n",
              "      <td>1.800000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>24.111271</td>\n",
              "      <td>4.400000</td>\n",
              "      <td>23.439238</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
              "count         123.000000        123.000000         124.000000   \n",
              "mean            5.821221          2.764442           3.909994   \n",
              "std             2.428445          2.174626           2.484749   \n",
              "min           -11.601111        -14.870849           1.100000   \n",
              "25%             5.100000          2.700000           1.600000   \n",
              "50%             5.700000          3.000000           4.250000   \n",
              "75%             6.400000          3.300000           5.100000   \n",
              "max            24.111271          4.400000          23.439238   \n",
              "\n",
              "       petal width (cm)      target  \n",
              "count        120.000000  125.000000  \n",
              "mean           1.186667    0.984000  \n",
              "std            0.758474    0.822898  \n",
              "min            0.100000    0.000000  \n",
              "25%            0.300000    0.000000  \n",
              "50%            1.300000    1.000000  \n",
              "75%            1.800000    2.000000  \n",
              "max            2.500000    2.000000  "
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "ktQDlu3IGLmC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "ktQDlu3IGLmC",
        "outputId": "8c032901-cb2c-46ff-a042-f7943059bc9a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>-11.601111</td>\n",
              "      <td>3.8</td>\n",
              "      <td>6.4</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>24.111271</td>\n",
              "      <td>2.3</td>\n",
              "      <td>4.4</td>\n",
              "      <td>1.3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
              "22         -11.601111               3.8                6.4               2.0   \n",
              "97          24.111271               2.3                4.4               1.3   \n",
              "\n",
              "    target  \n",
              "22       2  \n",
              "97       1  "
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[(df[\"sepal length (cm)\"]>10) | (df[\"sepal length (cm)\"]<0)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "dqG2H5NAE4Sk",
      "metadata": {
        "id": "dqG2H5NAE4Sk"
      },
      "outputs": [],
      "source": [
        "# Importar knn\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "# Rellenar datos atípicos usando el promedio de su clase\n",
        "df=pd.read_csv('iris_train.csv')\n",
        "df[(df > 10) | (df < 0)] = None\n",
        "\n",
        "# Rellenar nulos con KNN por clase\n",
        "df_filled = df.copy()\n",
        "\n",
        "for clase in df.iloc[:, -1].unique():\n",
        "    mascara = df.iloc[:, -1] == clase\n",
        "    imputer = KNNImputer(n_neighbors=5)\n",
        "    df_filled.loc[mascara, df.columns[:-1]] = imputer.fit_transform(df.loc[mascara, df.columns[:-1]])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "IQDOfdneG3DM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "IQDOfdneG3DM",
        "outputId": "c2fa5fa4-caff-44e9-c366-ee1223592178"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>125.000000</td>\n",
              "      <td>125.000000</td>\n",
              "      <td>125.000000</td>\n",
              "      <td>125.000000</td>\n",
              "      <td>125.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5.820960</td>\n",
              "      <td>3.041760</td>\n",
              "      <td>3.753120</td>\n",
              "      <td>1.196160</td>\n",
              "      <td>0.984000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.817912</td>\n",
              "      <td>0.446658</td>\n",
              "      <td>1.766489</td>\n",
              "      <td>0.754991</td>\n",
              "      <td>0.822898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>4.300000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>5.100000</td>\n",
              "      <td>2.800000</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.700000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.200000</td>\n",
              "      <td>1.300000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.400000</td>\n",
              "      <td>3.300000</td>\n",
              "      <td>5.100000</td>\n",
              "      <td>1.800000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7.700000</td>\n",
              "      <td>4.400000</td>\n",
              "      <td>6.900000</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
              "count         125.000000        125.000000         125.000000   \n",
              "mean            5.820960          3.041760           3.753120   \n",
              "std             0.817912          0.446658           1.766489   \n",
              "min             4.300000          2.000000           1.100000   \n",
              "25%             5.100000          2.800000           1.600000   \n",
              "50%             5.700000          3.000000           4.200000   \n",
              "75%             6.400000          3.300000           5.100000   \n",
              "max             7.700000          4.400000           6.900000   \n",
              "\n",
              "       petal width (cm)      target  \n",
              "count        125.000000  125.000000  \n",
              "mean           1.196160    0.984000  \n",
              "std            0.754991    0.822898  \n",
              "min            0.100000    0.000000  \n",
              "25%            0.300000    0.000000  \n",
              "50%            1.300000    1.000000  \n",
              "75%            1.800000    2.000000  \n",
              "max            2.500000    2.000000  "
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_filled.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "x9Eb0d31EN8D",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9Eb0d31EN8D",
        "outputId": "e61b4f5b-5aa3-41ff-fdbc-067e6e01c6a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.96"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X,y=df_filled.iloc[:,:-1].values,df_filled.iloc[:,-1].values\n",
        "\n",
        "rf=RandomForest(n_estimators=100, max_depth='sqrt', random_state=17)\n",
        "rf.fit(X,y)\n",
        "\n",
        "y_hat=rf.predict(X)\n",
        "accuracy_score(y,y_hat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "2SNDVoGzISAG",
      "metadata": {
        "id": "2SNDVoGzISAG"
      },
      "outputs": [],
      "source": [
        "with open(\"../models/modelo.pkl\", \"wb\") as f:\n",
        "    pickle.dump(rf, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5c9fc70",
      "metadata": {
        "id": "c5c9fc70"
      },
      "source": [
        "### Elemento 1 - Preguntas teóricas"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0769e4e8",
      "metadata": {
        "id": "0769e4e8"
      },
      "source": [
        "**¿Por qué el bagging ayuda a reducir la varianza del modelo?**\n",
        "\n",
        "El bagging promedia las predicciones de los numerosos árboles de decisión, cada uno entrenado en una versión ligeramente diferente de los datos obtenidos con Bootstrap. Los árboles de decisión individuales son propensos a la alta varianza, lo que significa que pequeños cambios en los datos de entrenamiento pueden alterar drásticamente su estructura y predicciones, llevando al sobreajuste. Al entrenar cada árbol en una muestra Bootstrap distinta, se genera diversidad entre ellos, haciendo que cometan errores diferentes. Cuando se agregan estas predicciones, los errores específicos de cada árbol tienden a cancelarse, dando como resultado un modelo de ensamble final mucho más estable, menos sensible al ruido de la muestra de entrenamiento particular, y con una varianza general más baja, lo que mejora su capacidad de generalización a datos no vistos.\n",
        "\n",
        "**¿Qué efecto tiene limitar el número de variables consideradas en cada división?**\n",
        "\n",
        "Limitar el número de variables consideradas aumenta su diversidad. Al no permitir que variables muy predictivas dominen todas las divisiones en todos los árboles, se fuerza a cada árbol a explorar diferentes conjuntos de características y, por lo tanto, a aprender estructuras y reglas distintas. Esta menor correlación entre los árboles hace que el proceso de agregación (voto o promedio) sea más efectivo para cancelar los errores individuales, lo que resulta en una reducción significativa de la varianza del modelo final y una mejor capacidad de generalización. Adicionalmente, evaluar menos variables en cada nodo acelera el proceso de entrenamiento de cada árbol.\n",
        "\n",
        "**¿Cómo cambia el desempeño al incrementar el número de árboles en el ensamble?**\n",
        "\n",
        "Al incrementar el número de árboles en un Random Forest, el desempeño del modelo puede mejorar debido a una reducción en la varianza, ya que promediar o votar las predicciones de más árboles ayuda a cancelar errores. Sin embargo, esto no mejora infinitamente, ya que tiende a estabilizarse después de cierto número de árboles. Por lo tanto, añadir más árboles aumenta la complejidad sin agregar muchos beneficios adicionales en las métricas."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1017feed",
      "metadata": {
        "id": "1017feed"
      },
      "source": [
        "## Elemento 2 - Comparativa con scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "09eb4078",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09eb4078",
        "outputId": "d2ee7183-ecc7-4322-ed14-2ec082655c3c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# comparar con sklearn\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf_sklearn=RandomForestClassifier(n_estimators=100, max_depth=None, random_state=17)\n",
        "rf_sklearn.fit(X,y)\n",
        "\n",
        "y_hat=rf_sklearn.predict(X)\n",
        "accuracy_score(y,y_hat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "ff1cd961",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff1cd961",
        "outputId": "a5af9c00-9fe2-4eb6-cd0f-898e7e476613"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters:  {'max_depth': None, 'n_estimators': 50}\n",
            "Best accuracy:  0.944\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150, 200,400],  # Number of trees in the forest\n",
        "    'max_depth': [None, 5, 10, 15]  # Maximum depth of the trees\n",
        "}\n",
        "\n",
        "# Create a GridSearchCV object\n",
        "# We use the custom RandomForest class\n",
        "grid_search = GridSearchCV(RandomForest(random_state=17), param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "# Print the best parameters and the best score\n",
        "print(\"Best parameters: \", grid_search.best_params_)\n",
        "print(\"Best accuracy: \", grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "7967ee6b",
      "metadata": {
        "id": "7967ee6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matriz de Confusión (scikit-learn):\n",
            "[[43  0  0]\n",
            " [ 0 41  0]\n",
            " [ 0  0 41]]\n",
            "\n",
            "Reporte de Clasificación (scikit-learn):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        43\n",
            "           1       1.00      1.00      1.00        41\n",
            "           2       1.00      1.00      1.00        41\n",
            "\n",
            "    accuracy                           1.00       125\n",
            "   macro avg       1.00      1.00      1.00       125\n",
            "weighted avg       1.00      1.00      1.00       125\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Make predictions using the scikit-learn RandomForestClassifier\n",
        "y_pred_sklearn = rf_sklearn.predict(X)\n",
        "\n",
        "# Calculate and print the confusion matrix for the scikit-learn model\n",
        "conf_matrix_sklearn = confusion_matrix(y, y_pred_sklearn)\n",
        "print(\"Matriz de Confusión (scikit-learn):\")\n",
        "print(conf_matrix_sklearn)\n",
        "\n",
        "# Calculate and print the classification report for the scikit-learn model\n",
        "class_report_sklearn = classification_report(y, y_pred_sklearn)\n",
        "print(\"\\nReporte de Clasificación (scikit-learn):\")\n",
        "print(class_report_sklearn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "7a0045cc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a0045cc",
        "outputId": "229231d2-5d95-4102-91d1-5a58748debfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matriz de Confusión:\n",
            "[[42  1  0]\n",
            " [ 0 39  2]\n",
            " [ 0  2 39]]\n",
            "\n",
            "Reporte de Clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99        43\n",
            "           1       0.93      0.95      0.94        41\n",
            "           2       0.95      0.95      0.95        41\n",
            "\n",
            "    accuracy                           0.96       125\n",
            "   macro avg       0.96      0.96      0.96       125\n",
            "weighted avg       0.96      0.96      0.96       125\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Make predictions on the training data (you might want to use a separate test set)\n",
        "y_pred = rf.predict(X)\n",
        "\n",
        "# Calculate and print the confusion matrix\n",
        "conf_matrix = confusion_matrix(y, y_pred)\n",
        "print(\"Matriz de Confusión:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Calculate and print the classification report (includes precision, recall, f1-score)\n",
        "class_report = classification_report(y, y_pred)\n",
        "print(\"\\nReporte de Clasificación:\")\n",
        "print(class_report)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20c15c0a",
      "metadata": {
        "id": "20c15c0a"
      },
      "source": [
        "### Elemento 2 - Preguntas teóricas"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d82f1a7",
      "metadata": {
        "id": "3d82f1a7"
      },
      "source": [
        "**¿Qué diferencias cuantitativas y cualitativas se observan entre tu implementación y la de sklearn?**\n",
        "\n",
        "Cuantitativamente, la implementación propia alcanzó un 96% de accuracy en el conjunto de entrenamiento y un 94.4% de accuracy promedio en validación cruzada (usando GridSearchCV), mientras que la versión de scikit-learn logró un 100% de accuracy en el mismo conjunto de entrenamiento, sugiriendo un posible sobreajuste o una mayor capacidad para capturar la complejidad de los datos de entrenamiento. Cualitativamente, la implementación propia se enfoca en replicar la lógica central del bagging y la votación usando `DecisionTreeClassifier` como base, mientras que scikit-learn es una implementación altamente optimizada (probablemente en Cython/C), más rápida, con más funcionalidades (como `n_jobs` para paralelización) y potencialmente con heurísticas internas más refinadas para la construcción de árboles y manejo de características.\n",
        "\n",
        "**¿Cómo influyen los parámetros n_estimators y max_features en el desempeño del modelo?**\n",
        "\n",
        "`n_estimators` controla el número de árboles en el bosque; incrementarlo generalmente reduce la varianza y mejora la estabilidad del modelo al promediar más predicciones, aunque el beneficio disminuye a partir de cierto punto y aumenta el costo computacional. `max_features` limita el número de características consideradas en cada división, incrementando la diversidad entre los árboles y reduciendo su correlación, ayudando a disminuir la varianza general del ensamble a costa de un posible ligero aumento en el sesgo de cada árbol individual; valores comunes como 'sqrt' buscan un equilibrio.\n",
        "\n",
        "**¿Por qué el modelo de sklearn suele ser más rápido o más preciso?**\n",
        "\n",
        "El modelo de scikit-learn suele ser más rápido porque está implementado con optimizaciones de bajo nivel (Cython/C) y permite paralelizar el entrenamiento de los árboles a través del parámetro `n_jobs`, aprovechando múltiples núcleos de CPU. Puede ser más preciso debido a optimizaciones en el algoritmo de construcción del árbol base, heurísticas más avanzadas para encontrar divisiones, manejo eficiente de datos o estrategias predeterminadas para parámetros no especificados; sin embargo, la implementación propia demostró un buen desempeño en validación cruzada (94.4%) y un buen accuracy general (96%).\n",
        "\n",
        "**¿Tu implementación mantiene el mismo comportamiento al modificar la semilla aleatoria?**\n",
        "\n",
        "No, la implementación no mantendrá exactamente el mismo comportamiento si se modifica la semilla aleatoria (`random_state`). Random Forest utiliza aleatoriedad en dos puntos clave: al crear las muestras bootstrap para cada árbol y al seleccionar el subconjunto de características (`max_features`) en cada nodo. Cambiar la semilla inicial alterará las muestras y las características seleccionadas, resultando en un bosque compuesto por árboles diferentes, lo que probablemente conducirá a ligeras variaciones en las métricas de desempeño y en las predicciones específicas, aunque las tendencias generales del modelo deberían ser similares.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd8832f4",
      "metadata": {
        "id": "bd8832f4"
      },
      "source": [
        "## Elemento 3 - Creación y despliegue de la API"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a174e868",
      "metadata": {},
      "source": [
        "La creación de la API se encuentra en app.py"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04343311",
      "metadata": {
        "id": "04343311"
      },
      "source": [
        "### Elemento 3 - Preguntas teóricas"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa7eb7a4",
      "metadata": {
        "id": "fa7eb7a4"
      },
      "source": [
        "**¿Qué ventajas ofrece exponer un modelo como servicio web?**\n",
        "\n",
        "Exponer un modelo como servicio web permite que sus predicciones puedan ser utilizadas desde cualquier aplicación o sistema remoto mediante solicitudes HTTP, sin necesidad de acceder directamente al código o al entorno de desarrollo. Esto facilita la integración con otros servicios, la automatización de procesos y la actualización del modelo sin modificar las aplicaciones cliente. Además, ofrece escalabilidad, ya que el modelo puede atender múltiples peticiones simultáneas en la nube, y mantenibilidad al centralizar el modelo en un único punto de acceso.\n",
        "\n",
        "**¿Qué riesgos o limitaciones pueden surgir si no se valida correctamente la entrada del usuario?**\n",
        "\n",
        "Si no se valida adecuadamente la información que envía el usuario al endpoint `/predict`, pueden surgir errores de ejecución, resultados erróneos o vulnerabilidades de seguridad, como inyección de código o ataques de denegación de servicio (DoS). Una validación deficiente puede hacer que el servicio se vuelva inestable o que devuelva respuestas incoherentes, afectando la confiabilidad del modelo y la disponibilidad de la API.\n",
        "\n",
        "**¿Por qué es importante incluir un endpoint de /health en una API?**\n",
        "\n",
        "El endpoint `/health` es esencial para el monitoreo y diagnóstico del servicio, ya que permite confirmar rápidamente si la API está activa y funcionando correctamente. Este punto de control se usa comúnmente por plataformas de despliegue o sistemas de supervisión automática para detectar fallos, reiniciar el servicio si es necesario y garantizar que el modelo esté disponible. Además, simplifica la verificación manual por parte del equipo de desarrollo antes de realizar pruebas o actualizaciones.\n",
        "\n",
        "**¿Cómo podrías garantizar que tu servicio mantenga disponibilidad bajo diferentes condiciones?**\n",
        "\n",
        "Para mantener la disponibilidad, es necesario aplicar buenas prácticas de despliegue y diseño, validar correctamente las solicitudes, manejar excepciones para evitar caídas inesperadas, usar un servidor confiable en la nube y configurar reinicios automáticos en caso de error. También se puede mejorar la disponibilidad mediante pruebas de carga y concurrencia, optimización del rendimiento del modelo, y uso de mecanismos de escalado automático o balanceo de carga si se reciben muchas peticiones. Estas medidas aseguran que la API siga respondiendo aun bajo alta demanda o condiciones adversas."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
